---
layout: post
title:  "One-Shot Transfer of Affordance Regions? AffCorrs!"
date:   2022-09-14 20:21:59 +00:00
image: /images/affcorrs.gif
categories: research
authors: "<strong>Denis Hadjivelichkov</strong>, Sicelukwanda Zwane, Marc Deisenroth, Lourdes Agapito, Dimitrios Kanoulas"
author: "<strong>Denis Hadjivelichkov</strong>, Sicelukwanda Zwane, Marc Deisenroth, Lourdes Agapito, Dimitrios Kanoulas"
venue: "CoRL 2022"
---
Given a single reference image of an object with annotated affordance regions, can we segment semantically corresponding parts within a target scene? Our unsupervised model, AffCorrs, combines the useful properties of pre-trained DINO-ViT's image descriptors and cyclic correspondences. AffCorrs is able to find corresponding affordances both for intra- and inter-class one-shot part segmentation. This task is more difficult than supervised alternatives, but enables future work such as learning affordances via imitation and assisted teleoperation.